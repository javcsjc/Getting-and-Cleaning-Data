source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/complete.R')
complete("specdata", c(2,4,8,10,12))
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/complete.R')
complete("specdata", c(2,4,8,10,12))
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/complete.R')
complete("specdata", c(2,4,8,10,12))
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/complete.R')
complete("specdata", c(2,4,8,10,12))
complete("specdata", 1)
complete("specdata", 3)
complete("specdata", 30:25)
complete("specdata", 1)
complete("specdata", c(2,4,8,10,12))
complete("specdata", 30:25)
complete("specdata", 1)
submit()
submit()
submit()
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/complete.R')
?cor
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/corr.R')
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/corr.R')
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/corr.R')
cr <- corr("specdata", 150)
number_sets <- c(nrow(clean_data)) ##Calculates number of complete sets
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/corr.R')
corr("specdata", 150)
cr <- corr("specdata", 150)
head(cr)
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/corr.R')
cr <- corr("specdata", 150)
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/corr.R')
cr <- corr("specdata", 150)
summary(cr)
cr <- corr("specdata", 400)
head(cr)
summary(cr)
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/corr.R')
cr <- corr("specdata", 400)
head(cr)
summary(cr)
cr <- corr("specdata", 500)
summary(cr)
submit()
submit()
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/corr.R')
cr <- corr("specdata", 500)
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/corr.R')
cr <- corr("specdata", 500)
cr <- corr("specdata", 5000)
summary(cr)
length(cr)
cr <- corr("specdata", 150)
head(cr)
summary(cr)
cr <- corr("specdata", 400)
head(cr)
summary(cr)
cr <- corr("specdata")
summary(cr)
length(cr)
submit()
submit()
submit()
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/corr.R')
cr <- corr("specdata")
header(cr)
head(cr)
summary(cr)
length(cr)
source(https://github.com/javcsjc/ProgrammingAssignment2.git)
link(https://github.com/javcsjc/ProgrammingAssignment2.git)
ls()
library(datsets)
library(datasets)
data(iris)
?iris
ls()
list.files(iris)
file.list(iris)
list.files()
list.files(iris/)
mean(iris)
data(iris)
mean(iris)
iris_mean <- mean(iris)
read.csv(iris)
read.csv(data/iris)
getwd()
dim(iris)
summary(iris)
colMeans(iris)
summary(iris)
iris
virginica <- c(iris$Species == virginica)
virginica <- c(iris$Species == "virginica")
virginica
summary(virginica)
dim(virginica)
virginica <- data.frame (iris[, 1:5], iris$Species == virginica)
virginica
virginica <- data.frame (iris[, 1:5], iris$Species == virginica,)
virginica <- data.frame (iris[, 1:5], where iris$Species == virginica)
virginica <- data.frame (iris$Species == virginica)
virginica <- data.frame (iris, iris$Species == virginica)
virginica <- data.frame (iris, iris$Species == "virginica")
virginica
virginica <- subset(iris, iris#Species == "virginica")
virginica <- subset(iris, iris#Species == "virginica")
virginica
swirl()
library(swirl)
rm(list=ls())
ls()
getwd()
swirl()
x
x[1:10]
x[is.na(x)]
y <- x[!is.na(x)]
y
y[y>0]
x[x>0]
x[!is.na(x)& x>0]
x <-c(3,5,7)
x <- x[c(3,5,7)]
skip
[c(3,5,7)]
x <-
skip()
x[0]
x[3000]
x[c(-2, -10)]
x[-c(2,10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical(vect, vect2)
vect["bar"]
vect[c("foo", "bar")]
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4,5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
my_matrix2 <- matrix(1:20,4,5,)
identical(my_matrix, my_matrix2)
patients <- c("Bill", "Gina", "Kelly", "Sean")
cbind(patients, my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my-data)
class(my_data)
cnames <- c('patient, 'age', 'weight', 'bp', 'rating', 'test'')
cnames <- c('patient', 'age', 'weight', 'bp', 'rating', 'test')
colnames(cnames, my_data)
colnames(my_data, cnames)
skip()
my_data
iris
virginica <- data.frame(iris, iris$Species == "virginica")
virginica
?subset
virginica <- subset(iris, Species == "virginica", select='Sepal.Length')
vriginica
virginica
virginica <- subset(iris, Species == "virginica", select='Sepal.Length':'Species')
virginica <- subset(iris, Species == "virginica", select='Sepal.Length','Species')
virginica <- subset(iris, Species == "virginica", select='Sepal.Length')
mean(virginica)
summary(vriginica)
summary(virginica)
virginica <- subset(iris, Species == "virginica", select='Sepal.Length', 'Sepal.Width')
virginica <- subset(iris, Species == "virginica", select=NULL)
virginica
virginica <- subset(iris, Species == "virginica", select=ALL)
virginica <- subset(iris, Species == "virginica", select=1:50
virginica <- subset(iris, Species == "virginica", select=1:5)
virginica
mean("virginica")
mean(virginica)
means(virginica)
summary(virginica)
colMeans(iris)
apply(iris,2, mean)
apply(iris[,1;4],1,mean)
apply(iris[,1:4],1,mean)
apply(iris[,1:4],2,mean)
?apply
iris
library(datasets)
data(mtcars)
?mtcars
lapply(mtcars, mean)
mean(mtcars$mpg, mtcars$cyl)
tapply(mtcars$cyl, mtcars$mpg, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
debug(ls)
debug(ls)
ls()
ls()
ls()
ls()
tapply(mtcars$cyl, average)
?average
tapply(mtcars$hp, mtcars$cyl== 4, mean)
lapply (mtcars$hp,mtcars$cyl[4], mean)
lapply (mtcars$hp,mtcars$cyl==4, mean)
mean(mtcars$hp, mtcars$cyl)
mean(mtcars$hp, mtcars$cyl, trim=1)
mtcars
mtcars(cyl=4)
fourcyl <- subset(mtcars, cyl == 4, select=1:4)
fourcyl
summary(fourcyl)
eightcyl <-subset(mtcars, cyl ==8, select=1:4)
summary(eightcyl)
eightcyl
with(mtcars, tapply(mpg,cyl,mean))
makevector <- function(x = numeric()){
m <- NULL
}
makevector <- function(x = numeric()){
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function ()m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/cachemean.R')
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/makevector.R')
library(swirl)
swirl()
getdata.data.ss06hid <- read.csv("~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/getdata-data-ss06hid.csv")
View(getdata.data.ss06hid)
data <- select(getdata.data.ss06hid, VAL, FES)
data
summary(data)
clean <- !is.na(data)
clean
summary(clean)
clean <- na.omit(data)
summary(clean)
clean
onemega <- filter(clean, VAL>=14)
onemega
onemega <- filter(clean, VAL=24)
onemega <- filter(clean, VAL==24)
onemega
clean
data
onemega <- filter(data, VAL==24)
onemega
data3 <- read.xlsx(Question3_Quiz1)
data3 <- download.file(Question3_Quiz1.xlsx)
list.files
list.files()
data3 <- download.file("Question3_Quiz1.xlsx")
data3 <- read.csv(Question3_Quiz1.csv)
data3 <- read.csv("Question3_Quiz1.csv")
data3
dat <- select(data3, Zip:Status)
sum(dat$Zip*dat$Ext, na.rm=T)
data <- xmlParse("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
require(XML)
data <- xmlParse("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
library(XML)
data <- xmlParse("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
install.packages("XML")
install.packages("plyr")
library("swirl", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("XML", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("xml2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("tidyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
list.files
list.files()
data5 <- read.csv("question5_quiz1.csv")
summary(data5)
head(data5)
tail(data5)
?fread
DT <- data5
DT[,mean(pwgtp15), by=SEX]
mean(DT[DT$SEX==1]$pwgtp15); mean(DT[DT$SEX==2]$pwgtp15)
tapply(DT$pwgtp15,DT$SEX, mean)
mean(DT$pwgtp15, by=DT$SEX)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
sapply(split(DT$pwgtp15, DT$SEX),mean)
system.time(tapply(DT$pwgtp15, DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15, DT$SEX),mean))
install.packages("data.table")
system.time(sapply(split(DT$pwgtp15, DT$SEX),mean))
system.time(tapply(DT$pwgtp15, DT$SEX,mean))
library(swirl)
swirl()
submit()
install.packages("RMySQL")
library("RMySQL", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
source("http://bioconductor.org/biocLite.R")
biocLite()
library(rhdf5)
library("httr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
httr
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. To make your own application, register at at
#    https://github.com/settings/applications. Use any URL for the homepage URL
#    (http://github.com is fine) and  http://localhost:1410 as the callback url
#
#    Replace your key and secret below.
myapp <- oauth_app("github",
key = "d951ba467aff2365643e",
secret = "c92cc80090b1db33fc707d13fd03ade17ad3c576")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("httpuv")
library(httpuv)
library("httr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
oauth_endpoints("github")
myapp
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/myapp.R')
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken
str(raw_result)
library("Rcpp", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
myapp
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/myapp.R')
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
req
raw_results <- req
str(raw_results)
library("jsonlite", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
jsoned <- fromJSON(raw_results)
jsoned <- toJSON(raw_results)
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/myapp.R')
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/myapp.R')
req
raw_results <- req
str(raw_results)
jsoned <- fromJSON(raw_results)
str(raw_results)
jsoned
str(jsoned)
str("jsoned")
jsoned <- fromJSON(raw_results)
jsoned <- fromJSON(https://api.github.com/users/jtleek/repos)
jsoned <- fromJSON("https://api.github.com/users/jtleek/repos")
jsoned
jsoned <- fromJSON("https://api.github.com/users/jtleek/repos", datasharing)
jsoned <- fromJSON("https://api.github.com/users/jtleek/repos")
json1 <- content(datasharing)
json1 = content(raw_results)
json2 = jsonlite::fromJSON(toJSON(json1))
str(json2)
summary(json2)
json2
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos")
stop_for_status(req)
content(req)
raw_results <- req
json1 = content(raw_results)
json2 = jsonlite::fromJSON(toJSON(json1))
json2
str(json2)
header(json2)
summary(json2)
json2
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos")
stop_for_status(req)
content(req)????$created_at
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos")
stop_for_status(req)
content(req)????created_at
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos")
stop_for_status(req)
content(req)
content(req)
content(req[1])
content(req)[[1]]
raw_results <- req
json1 = content(raw_results)
json2 = jsonlite::fromJSON(toJSON(json1))
str(json2)
class(json2)
col.names(json2)
summary(json2)
summary("json2")
header(json2)
tail(json2)
library("tidyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("sqldf")
list.files
list.files()
acs <- read.csv("getdata-data-ss06pid.csv")
acs
sqldf("select pwgtp1 from acs")
library("sqldf", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
sqldf("select pwgtp1 from acs")
sqldf("select * from acs where AGEP < 50 and pwgtp1")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select * from acs where AGEP < 50 and pwgtp1")
sqldf("select pwgtp1 from acs where AGEP < 50")
unique(acs$AGEP)
sort(unique(acs$AGEP))
sqldf("select distinct AGEP from acs")
?nchar
contact <- Get("http://biostat.jhsph.edu/~jleek/contact.html")
contact <- GET("http://biostat.jhsph.edu/~jleek/contact.html")
contact''
contact
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
htmlCode
nchar(htmlCode[10,], htmlCode[20,], htmlCode[30,], htmlCode[100,])
nchar(htmlCode[10], htmlCode[20], htmlCode[30], htmlCode[100])
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
q5 = url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for")
class(q5)
q5
q5 <- GET("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for")
q5
str(q5)
close(con)
close(q5)
close ("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for")
close(con)
close.connection(q5)
library("dplyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("highr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("httpuv", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("httr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("jsonlite", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("RSQLite", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("sqldf", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages(readr)
install.packages("readr")
library("readr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/fixed_width.R')
source('~/Desktop/Data Science Specialization - Coursera/datasciencecoursera/fixed_width.R')
head(x)
column4 <- select(x, V4)
column4
total <- sum(column4)
total
install.packages(Hmisc)
install.packages(hmisc)()
install.packages(hmisc)
install.packages("Hmisc")
library(Hmisc)
getwd()
list.files()
ls
ls()
?list.files
list.dirs
list.dirs()
?setwd
setwd("./UCI HAR Dataset")
getwd()
list.files()
Readme.txt
subject_test <- read.csv("./test/subject_test.txt")
class(subject_test)
ls(subject_test)
head(subject_test)
summary(subject_test)
str(subject_test)
col.names(subject_test)
library("tidyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
tail(subject_test)
x_test <- read.csv("./test/x_test.txt")
summary(x_test)
str(x_test)
y_test <- read.csv("./test/y_test.txt")
str(y_test)
y_test
View(subject_test)
View(x_test)
View(y_test)
subject_train <- read.csv("./train/subject_train.txt")
View(subject_train)
x_train <- read.csv("./train/x_train.txt")
View(x_train)
y_train <- read.csv("./train/y_train.txt")
View(y_train)
